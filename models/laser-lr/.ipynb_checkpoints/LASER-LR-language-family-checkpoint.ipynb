{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASER + Logistic Regresion (Monolingual-Train-Monolingual-Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that you have the API running before running this.\n",
    "def generate_LASER_embedding(sequence, lang='en'):\n",
    "    if not sequence or len(sequence) < 0:\n",
    "        print('Please pass in an input sequence to generate an embedding.')\n",
    "    url = \"http://128.61.46.191:80/vectorize\"\n",
    "    params = {\"q\": sequence, \"lang\": lang}\n",
    "    resp = requests.get(url=url, params=params).json()\n",
    "    arr = np.array(resp[\"embedding\"])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_for_dataset(ifname, lang):\n",
    "    '''\n",
    "    Generates embeddings and saves it into a CSV given an input file path and a language.\n",
    "    '''\n",
    "    print(f'Generating input embeddings for {ifname}')\n",
    "    embeddings = []\n",
    "    df = pd.read_csv(f'{DATA_DIR}/{ifname}')\n",
    "    print(f'Total embeddings to generate: {df.shape[0]}')\n",
    "    for idx, row in df.iterrows():\n",
    "        if (idx+1) % (df.shape[0] // 25) == 0:\n",
    "            print(f'Completed {idx+1} embeddings')\n",
    "        embedding = generate_LASER_embedding(row['text'], lang=lang)[0]\n",
    "        embedding = np.append(embedding, [int(row['hs'])])\n",
    "        embeddings.append(embedding)\n",
    "    embeddings = np.array(embeddings)\n",
    "    # Save each entry of the embedding array as a column in the dataframe.\n",
    "    columns = [str(i) for i in range(1024)]\n",
    "    columns.append('hs')\n",
    "    embedding = pd.DataFrame(embeddings, columns=columns)\n",
    "    embedding.hs = embedding.hs.astype(int)\n",
    "    ofname = ifname.split('.')[0] + '_embeddings.csv'\n",
    "    embedding.to_csv(f'{DATA_DIR}/{ofname}', index=False)\n",
    "    print(f'Wrote embedding dataframe to {DATA_DIR}/{ofname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_LR_model(ifname, lang, c=0.01):\n",
    "    df = pd.read_csv(f'{DATA_DIR}/{ifname}')\n",
    "    print(f'Training model for {lang} on {ifname}')\n",
    "    X_cols = [str(i) for i in range(1024)]\n",
    "    X, y = df[X_cols], df['hs']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "    model = LogisticRegression(C=c, solver='lbfgs', class_weight='balanced', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Training complete!')\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    f_score = f1_score(y_test, y_pred ,average='macro')\n",
    "    print(f'Macro F1: {f_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/all-processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French (Ousidhoum et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifname = 'B_french_ousidhoum_processed.csv'\n",
    "df = pd.read_csv(f'{DATA_DIR}/{ifname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating input embeddings for B_french_ousidhoum_processed.csv\n",
      "Total embeddings to generate: 1028\n",
      "Completed 41 embeddings\n",
      "Completed 82 embeddings\n",
      "Completed 123 embeddings\n",
      "Completed 164 embeddings\n",
      "Completed 205 embeddings\n",
      "Completed 246 embeddings\n",
      "Completed 287 embeddings\n",
      "Completed 328 embeddings\n",
      "Completed 369 embeddings\n",
      "Completed 410 embeddings\n",
      "Completed 451 embeddings\n",
      "Completed 492 embeddings\n",
      "Completed 533 embeddings\n",
      "Completed 574 embeddings\n",
      "Completed 615 embeddings\n",
      "Completed 656 embeddings\n",
      "Completed 697 embeddings\n",
      "Completed 738 embeddings\n",
      "Completed 779 embeddings\n",
      "Completed 820 embeddings\n",
      "Completed 861 embeddings\n",
      "Completed 902 embeddings\n",
      "Completed 943 embeddings\n",
      "Completed 984 embeddings\n",
      "Completed 1025 embeddings\n",
      "Wrote embedding dataframe to ../data/all-processed/B_french_ousidhoum_processed_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "generate_embeddings_for_dataset(ifname, 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for French on B_french_ousidhoum_processed_embeddings.csv\n",
      "Training complete!\n",
      "Accuracy: 0.6516129032258065\n",
      "Macro F1: 0.5826685281212605\n"
     ]
    }
   ],
   "source": [
    "train_and_test_LR_model('B_french_ousidhoum_processed_embeddings.csv', 'French')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsn",
   "language": "python",
   "name": "dsn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
